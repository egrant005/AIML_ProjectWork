## AIML_ProjectWork
Repository to store all the Jupyter notebooks from project work associated with the AI/ML Post-graduate program offered by The University of Texas and Great Learning

### 1. Data Analysis Techniques
*MovieLens Project (1):* A project that introduced basic Exploratory Data Analysis (EDA), Visualization, and Database Management concepts using Python, Numpy, Pandas, Matplotlib, and Seaborn packages/libraries. The project used movie ratings data, provided by the "GroupLens Research Project" research group associated with the Department of Computer Science and Engineering at the University of Minnesota, and is often used to demonstrate collaborative filtering and other filtering solutions.

### 2. Supervised Learning Techniques
*Personal Loan Campaign Modelling Project (2):* A project that built upon the above, introducing more EDA techniques, and introduced Test/Train Data Splitting, Logistic Regression, and Metrics for evaluating the performance of models generated by the regression modelling using the SciKit Learn package/library. The project used basic customer demographic information, customer relationship information, and customer response information (accepted/rejected loan offer) from a previous personal loan campaign by Thera Bank - the objective being to use the customer data from this earlier campaign to create a Classification model to determine what customer type(s) were most likely to accept a personal loan if another campaign is launched in the future.

### 3. Ensemble Techniques
*Travel Package Purchase Prediction Project (3):* A project that introduced Classification and Regression Tree (CART) algorithms, Grid/Random Search Cross-Validation techniques to optimize tuning/pruning of Decision Trees, and Ensemble Techniques (i.e., Bagging, Boosting, and Stacking) using the SciKit Learn (Decision Tree, Random Forest, Bagging, Gradient Boosting, and AdaBoost Classifiers) and XGBoost packages/libraries. The project used basic customer demographic information, customer traveling preferences/choices, vacation package pitched to customers, and customer response information (accepted/rejected travel package offer) from a previous travel package promotion campaign by "Visit With Us" travel company - the objective being to use the customer data from this earlier campaign to create Classification model to determine what customer type(s) were most likely to accept certain vacation package type(s).

### 4. Feature Engineering, Model Selection, and Tuning Techniques
*Credit Card Users Churn Prediction Project (4):* A project that introduced Feature Engineering, Up/Down Sampling (for imbalanced datasets), and Regularization techniques as well as Pipelines, Modeling Selection, and Hyper-Parameter Tuning using the SciKit Learn and Imbalanced-Learn packages/libraries. The project used basic customer demographic information, customer relationship information, historical financial and/or transaction data, and whether or not they are still current credit card holders for Thera Bank - the objective being to use the customer data to create a Classification model to determine whether a customer was likely to keep or cancel their credit card with the bank. 

### 5. Unsupervised Learning/Clustering Techniques
*ALL Life Bank Marketing Campaign Modelling Project (5):* A project that introduced Clustering Techniques (e.g., K-Means Clustering and Hierarchical Clustering), Distance Measurements (e.g., Manhattan, Euclidean, etc.), Data Scaling, Principal Component Analysis (PCA) and other Dimensionality Reduction Techniques using SciKit Learn, SciPy, and Yellowbrick packages/libraries. The project used basic customer transactional information as well as basic customer support related information for ALL Life bank - the objective being to determine the characteristics that best describe each of the N groups/segments of customers associated with their bank.

### 6. Neural Networks
*Bank Churn Prediction Project (6):* A project that introduced Deep Learning, using Artificial Neural Networks (ANN), and how to preprocess data to make it ready for an ANN to perform classification tasks using Google Tensorflow and Keras packages/libraries within the Google Colab python development environment. The project used customer demographic information, customer relationship information, and whether or not a customer is still a current bank customer for a Bank (open-source Kaggle dataset) - the objective being to use the customer data to create a Classification model to determine whether a customer was likely to remain a Bank customer. 

### 7. Computer Vision
*Plant Seedlings Image Classification Project (7):* A project that introduced Convolutional Neural Networks (CNN), convolution operators, and aspects of working with and processing digital images prior to classification using Google Tensorflow and Keras, as well as SciPy packages/libraries. The project used a subset of the open-source Kaggle dataset containing digital images of crop seedlings and common weeds, provided by the Aarhus University Signal Processing group, at various stages of plant growth - the objective being to use the filtered/processed digital images to create a Classification model to identify the plant species correctly.

### 8. Natural Language Processing (NLP)
*US Airline Twitter Sentiment Project (8):* A project that introduced NLP, aspects of working with and processing text-heavy content, as well as the tools used to Vectorize the text data before building a Tex Classification model or running Sentiment Analysis using NLTK, SciKit Learn, and BeautifulSoup packages/libraries. The project used a dataset that contained Twitter feedback provided by US Airline customers as well as a Sentiment Analysis prediction for each "Tweet" - the objective being to use the Twitter feedback to create a Classification model that identifies the Sentiment of each "Tweet" as Positive, Negative, or Neutral (i.e., essentially trying to build a model that will match the original Sentiment Analysis).
